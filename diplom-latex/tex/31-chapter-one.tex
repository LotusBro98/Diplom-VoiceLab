\chapter{Обзор существующих подходов и теоретическая справка}
\label{cha:ch_1}


\section{Архитектуры нейронных сетей для синтеза речи}
Современные решения для преобразования текста в речь в основном устроены следующим образом: (cм. Рисунок \ref{fig:tts_pipeline})

\begin{enumerate}
    \item В начале текст токенизируется - преобразуется из строкового формата в последовательность лексем - токенов
    \item токенизированный текст преобразуется с помощью нейросети-энкодера во внутреннее признаковое представление
    \item используя текстовые признаки, нейросеть генерирует признаковое представление звука или спектрограмму. Этот модуль может быть многоуровненвым и сложным в зависимости от архитектуры.
    \item признакове представление звука декодируется в звуковой сигнал.
\end{enumerate}

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/tts_pipeline}
  \caption{Преобразование текста в речь}
  \label{fig:tts_pipeline}
\end{figure}

Также помимо задачи преобразования текста в речь, существуют задачи замены голоса, генерации музыки, перевода с сохранением голоса и прочие.
Их пайплайн устроен похожим образом, но какие-то части могут отличаться. 
Отметим, что в любой из перечисленных задач неотъемлемой частью пайплайна является этап декодирования звука из признакового представления в аудиосигнал.




\subsection{Понятие спектрограммы}
Прежде чем продолжить рассмотрение современных подходов для синтеза речи, раскроем понятие спектрограммы.

\textbf{Спектрограмма} - это двумерный массив данных, представляющий из себя разложение сигнала по спектру, изменяющееся во времени.
Такое разложение можно получить например с помощью оконного преобразования Фурье или вейвлет-преобразования. 
По горизонитальной оси отложено время в линейной шкале. По вертикальной оси отложены частоты, в некоторой шкале, не обязательно линейной.
На практике используются линейная, логарифмическая и мел-шкала.
\begin{itemize}
  \item Линейная шкала используется обычно в обратимых алгоритмоах или как разложение для передачи многоканальной информации в одном сигнале.
  \item Логарифмическая шкала используется в музкальных приложениях и редакторах.
  \item мел-шкала используется для анализа голоса. Она построена на исследованиях чувствительности человеческого слуха к изменению частоты.
\end{itemize}

На рисунке \ref{fig:log_spec} изображен пример спектрограммы в логарифмической шкале, а на рисунке \ref{fig:mel_spec} - в мел-шкале.
\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/log_spec}
  \caption{Спектрограмма записи игры на металлофоне в логарифмической шкале частот с указанием нот}
  \label{fig:log_spec}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/mel_spec}
  \caption{Спектрограмма записи голоса в мел-шкале}
  \label{fig:mel_spec}
\end{figure}




\subsection{Классификация моделей}
Рассмотрим основные подходы, использующиеся в современных решениях синтеза речи и их классификацию.


\subsubsection{По формату промежуточного представления}
По формату промежуточного представления методы делятся на несколько типов:

\textbf{Генераторы спектрограмм} подразумевают генерацию спектрограммы с последующим преобразованием спектрограммы в звуковой сигнал. Примеры таких моделей:
\begin{itemize}
  \item Tacotron 2 (Google, 2017) \cite{Tacotron2} - классическая модель, использующая последовательное преобразование текста в мел-спектрограмму, с последующим применением вокодера для декодирвоания звука.
  \item FastSpeech 2 (Microsoft, 2019–2020) \cite{FastSpeech2} - Ускоренные и более стабильные версии Tacotron.
  \item Riffusion (2022) \cite{Riffusion} - Диффузионная модель, генерирующая песни и инструментальную музыку в виде спектрограмм с последующим декодированием в звук.
  \item TalkNet (2020, NVIDIA) \cite{TalkNet} - Полносверточная text-to-speech модель
\end{itemize}

\textbf{Генераторы в латентное представление} с последующим декодированием в звук с помощью нейронного декодера подразумевают 
генерацию латентного признакого представления, чем-то отдаленно схожего со спектрограммой, но сформированного отдельно обученным автоэнкодером.

\begin{itemize} 
  \item NaturalSpeech 2 (Microsoft, 2023) \cite{NaturalSpeech2} - Современная модель на основе латентных диффузий для синтеза речи и пения
  \item Kokoro-TTS (2025) \cite{kokoro}- это современная, компактная и высокоэффективная модель синтеза речи, разработанная для генерации естественного звучания при минимальных вычислительных затратах
\end{itemize}

\textbf{Генераторы токенов для нейронного кодека} схожи по принципу работы с генеративными трансформерами - основная генеративная модель создает последовательность токенов, 
которая потом преобразуется в звук с помощью нейросетевого кодека.

Пример такого кодека - EnCodec (Meta AI, 2022) \cite{encodec}. Он предназначен для сжатия и восстановления аудиосигналов, кодирует звук в дискретное латентное пространство (токены).

\begin{itemize} 
  \item Bark (Suno AI) \cite{SunoAI_Bark_2023} - Трансформерная генеративная модель, синтезирующая музыку и песни по заданному тексту и указаниям.
  \item Voicebox (2023, Meta AI) \cite{le2023voicebox} - Модель, способная генерировать, изменять и редактировать речь в различных стилях.
  \item VALL-E (Microsoft, 2023) \cite{Valle} - генерация речи с имитацией голоса на основе аудиопримера, на базе условной языковой модели.
\end{itemize}

\textbf{Одностадийные end-to-end аудиогенераторы} синтезируют звук напрямую, минуя стадию спектрограммы или отдельного декодера из латентного пространства.

\begin{itemize} 
  \item WaveNet (DeepMind, 2016) \cite{WaveNet} - Первая модель, которая напрямую генерировала звук по аудиосэмплам. Медленная, так как работает сэмпл за сэмплом (для аудио с частотой дискретизации 24 000 Гц — таких генераций должно быть 24 тысячи в секунду).
  \item DiffWave (Google, 2020) \cite{DiffWave} - Диффузионная модель, которая работает не со спектрограммой, а напрямую с аудиоволной. Высокое качество, но относительно медленная генерация.
\end{itemize}



\subsubsection{По принципу генерации промежуточного представления}
Если рассматривать принцип генерации промежуточного представления, то наиболее успешными являются трансформерные и диффузионные модели.
Также можно выделить полносверточные модели для обработки/восстановления звука, хотя существуют и полносверточные text-to-speech модели.


\textbf{Трансформерные генераторы} используют в качестве \textit{генератора} звукового представления GPT-подобный трансформер.
\begin{itemize}
  \item FastSpeech 2 (Microsoft, 2019–2020) \cite{FastSpeech2}
  \item Voicebox (2023, Meta AI) \cite{le2023voicebox}
  \item Bark (Suno AI) \cite{SunoAI_Bark_2023}
  \item Kokoro-TTS (2025) \cite{kokoro} - Поддерживает трансформеры в генераторе (настраиваемо)
  \item VALL-E (Microsoft, 2023) \cite{Valle} - генерация речи с имитацией голоса на основе аудиопримера, на базе условной языковой модели.
\end{itemize}

\textbf{Диффузионные генераторы} генерируют представление звука с помощью процесса обратной диффузии.
\begin{itemize}
  \item DiffWave (Google, 2020) \cite{DiffWave}
  \item NaturalSpeech 2 (Microsoft, 2023) \cite{NaturalSpeech2}
  \item Riffusion (2022) \cite{Riffusion}
\end{itemize}

\textbf{Полносверточные модели}
\begin{itemize} 
  \item TalkNet (2020, NVIDIA) \cite{TalkNet} - Полносверточная text-to-speech модель. В ней присутствуют отдельные полносверточные модели для предсказания длительности каждого текстового токена и модель для генерации спектрограмм. Очень быстрое обучение и синтез.
  \item Kokoro-TTS \cite{kokoro} в некоторых конфигурациях также может использовать полносверточный генератор с предсказанием длительности токенов, вместо трансформера.
  \item VoiceFixer (2022) \cite{VoiceFixer} - Восстановление повреждённой речи (например, из телефона, старых записей)
\end{itemize}


\section{Cуществующие вокодеры}
Среди существующих вокодеров, применяемых в современных системах синтеза речи, можно выделить следующие группы.

\textbf{Нейросетевые декодеры из спектрограммы} - HiFi-Gan \cite{hifigan}, WaveGlow \cite{WaveGlow} - восстанавливают звук из mel-спектрограммы
при помощи сверточных генеративных сетей. Информация в mel-спектрограмме может быть не полной или слегка искаженной, 
нейросеть все равно будет способна восстанавливать звук хорошего качества.

\textbf{Специализированные автоэнкодеры} - Сверточные сети, обученные под конкретную модель генератора. Так же способны генерировать звук хорошего качества, 
при этом часто работают быстрее, чем спектрограммные нейросетевые декодеры. Однако, под конкретную задачу и модель чаще всего требуется обучать отдельный 
автоэнкодер на большом объеме данных.

\textbf{Нейросетевые кодеки в дискретное латентное пространство} - EnCodec \cite{encodec} - кодирует звук в последовательность токенов. 
Может достигать хорошего качества в сочетании с трансформерами, и работает относительно быстро. Однако, в приложениях с большим разнообразием звуков и интонаций 
наблюдаются проблемы с качеством. А также этот кодек не работает с диффузионными и полносверточными генераторами.

\textbf{Алгоритмические декодеры из спектрограмм} - GriffinLim \cite{1164317} - Восстанавливает звук из спектрограммы (только магнитуды) в линейной шкале. 
Этот и другие алгоритмические декодеры могут восстанавливать звук точно без потерь. Но к сожалению при наложении небольших искажений,
пристуствующих в спектрограммах, сгенерированных нейросетью, появляются сильно заметные нежелательные артефакты (металлический звук, эхо), 
что делает такие декодеры неприменимыми в современных решениях. С другой стороны, такие декодеры заметно быстрее, чем нейросетевые, 
и могут быть использованы в приложениях для встраиваемых устройств с низкой вычислительной мощностью, когда можно пожертвовать качеством.


\subsection{Успехи и открытые проблемы}
Изучая успех упомянутых моделей среди сообщества и сравнивая качество синтезированного звука, можно сделать следующие выводы об успешности применения определенных технологий:

1. Существуют несколько технологий генерации звукового представления (диффузионные, трансформерные, полносверточные), способные синтезировать речь очень хорошего качества. Но такие технологии требуют больших вычислительных затрат. 
Есть оптимизированные решения, такие как Kokoro-TTS, достигающие высокого качества и высокой скорости работы за счет оптимизации архитектуры и размеров моделей, тщательной проработки и аккуратного обучения каждого компонента. 
Однако, у каждой технологии есть свои преимущества и недостатки, делающие ее более или менее пригодной для конкретной задачи.
Например: синтез музыки с множеством требований и указаний лучше всего удается диффузионным моделям. Полносверточные модели самые быстрые. 

2. Существует несколько типов вокодеров - использующие представление в виде спектрограммы, латентного представления, дискретного представления в виде токенов. Наилучшего качества в сочетании с нейросетями достигают нейросетевые вокодеры из латентного представления или спектрограммы. 
Алгоритмические вокодеры также существуют, но они неустойчивы к искажениям, которые неизбежно возникают при генерации представления с помощью нейросети, в результате чего появляются нежелательные артефакты.
Также для каждой технологии генерации подходит не любой тип промежуточного представления звука. Ниже рассмотрена совместимость технологий генерации с промежуточным представлением.

\begin{center}
\begin{tabular}{ c c c c }
                 & Спектрограмма & Латентное пр-е & Токены \\
    Диффузионные & +             & +              &        \\ 
  Трансформерные & +             & +              & +      \\  
 Полносверточные & +             & +              &     
\end{tabular}
\end{center}

Отсюда видно, что универсальными представлениями, работающими с любым типом генерации, являются спектрограмма и латентное векторное представление. 

3. Нейросетевой декодер из латентного пр-ва, обученный на одном наборе данных, 
может не подходить для применения на других данных (например на другом языке) или 
не подходить для конкретной задачи (учет интонации, акцента, персональности голоса говорящего).

4. Спектрограммные нейросетевые декодеры практически всегда требуют больших вычислительных затрат, чем из латентного пр-ва из-за избыточности информации. 
С другой стороны, в спектрограмме содержится достаточно информации для восстановления звука без потерь, 
и поэтому декодер из спектрограммы можно использовать для любой задачи, домена и технологии, и достигать наилучшего качества генерации.
Спектрограммное представление можно назвать \textit{универсальным} с точки зрения применимости технологии и задачи, но избыточным в плане вычислительных ресурсов 
(при использовании нейросетевого декодера).

5. Модели, генерирующие непосредственно звуковой сигнал, работают медленно и сложны в обучении. Практически всегда их можно разделить на две стадии - предобучение нейросетевого автоэнкодера в латентное пр-во и генерация на этом пр-ве.

6. Если бы существовал алгоритмический декодер спектрограммы, способный восстанавливать аудиосигнал с качеством, 
сопоставимым с современными нейросетевыми вокодерами, при этом устойчивый к искажениям во входных данных и обладающий более высокой скоростью работы, 
это могло бы упростить архитектуру TTS-систем, сократить вычислительные затраты и повысить доступность синтеза речи. 
Кроме того, использование стандартизированного формата спектрограмм позволило бы сосредоточить усилия на улучшении генератора, 
ускорить обучение и повысить воспроизводимость моделей.


\section{Спектральный анализ аудиосигналов}
В данном разделе рассмотрим теоретические основы алгоритмов построения спектрограмм и способы восстановления звукового сигнала из таких представлений.

Для начала рассмотрим \textbf{Оконное преобразование Фурье} или в англоязычной литературе Short-Time Fourier Transform (\textbf{STFT}) \cite{STFT}.

Оно представляет из себя двумерную функцию (от частоты и от времени), определяемую как преобразование Фурье от сигнала, умноженного на оконную функцию, сдвинутую во времени:

\begin{equation}
  \textbf{STFT}\{x(t)\} (\tau, \omega) = \int_{-\infty}^\infty x(t) w(t - \tau) e^{-i\omega t} dt
  \label{eq:stft_cont}
\end{equation}

Здесь \(w(t)\) - оконная функция. От ее выбора зависит разрешение спектрограммы по времени и по частоте. Иллюстрация работы STFT приведена на рисунке \ref{fig:mel_spec}.
В результате такого преобразования получается спектрограмма в линейной шкале, на которой можно увидеть, как разложение сигнала по частотам (спектр), изменяется во времени.

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/stft}
  \caption{Оконное преобразование Фурье (STFT)}
  \label{fig:stft}
\end{figure}

На практике используется дискретное оконное преобразование Фурье.
\begin{equation}
  \textbf{STFT}\{x[n]\} (m, k) = \sum_{n=0}^{N-1} x[n] w[n - m] e^{-2\pi i  \frac{k n}{N}} = \textbf{DFT}\{x[m:m+N] * w[0:N]\}(k)
  \label{eq:stft}
\end{equation}
Алгоритм его построения обычно следующий - из сигнала \(x[n]\) вырезается отрезок длиной \(N\) отсчетов со сдвигом по времени \(m\) отсчетов. 
Результат ДПФ выделенной части сигнала, умноженной на окно, присоединяется к массиву. В результате получается массив \([M \times K]\), 
представляющий из себя спектрограмму, как на рисунке \ref{fig:stft}

\begin{wrapfigure}{r}{0.4\textwidth}
  \includegraphics[width=0.9\linewidth]{figures/wavelet}
  \caption{Временное и спектральное представления вейвлета Морле \cite{MorleWavelet}}
  \label{fig:wavelet}
\end{wrapfigure}

Несложно показать, что преобразование является линейным, как и ДПФ.
Также можно представить каждый элемент $\textbf{STFT}\{x[n]\} (m, k)$ как свертку сигнала $x[n]$ с вейвлетом $w[n - m] e^{-2\pi i  \frac{k n}{N}}$.
И всю спектрограмму можно построить с помощью вейвлет-преобразования. Более того, для каждой частоты вейвлета можно выбирать свою ширину окна: 
$\psi_{k,m}(n) = w_k[n - m] e^{-2\pi i  \frac{k n}{N}}$. По такому принципу построено вейвлет-преобразование на основе вейвлета Морле \cite{MorleWavelet}, 
окном которого выбрана Гауссовская функция с шириной в несколько периодов соответствующей частоты. Это преобразование обратимо, так же как и STFT.

Рассмотрим влияние оконных функций на разрешение по времени и частоте. 
Оконная функция необходима для локализации события во временной области. 
Спектр оконной функции покажет, насколько хорошо событие локализовано в частотной области.
Кроме того, широкий спектр окна с паразитными "хвостами" создает связанность отдаленных частот. 
Небольшое искажение на одной частоте сильно влияет на другие частоты из-за таких эффектов, если не согласовано с этими частотами, 
чтобы в резульате интерференции получалось нужное значение. Примеры оконных функций и их спектров рассмотрены на рисунке \ref{fig:windows}

\begin{figure}[t]
  \centering
  \includegraphics[width=16cm]{figures/windows}
  \caption{Сравнение оконных функций}
  \label{fig:windows}
\end{figure}

По отношению к оконным функциям, а также любым сигналам, над которыми производится спектральное преобразование, сущетвует принцип неопределенности, который гласит, что
для дифференцируемых вещественных сигналов 
$x(t)$ с энергией $E$, для которых интеграл 
$t_{0} = \int \limits _{-\infty }^{\infty }tx^{2}(t)dt$ сходится и $\lim _{t\to \pm \infty }tx^{2}(t)=0$, произведение эффективной длительности сигнала 
$\Delta t$ и эффективной ширины полосы частот сигнала $\Delta f$ ограничено снизу \cite{Umnyashkin}:
\begin{equation}
  \Delta t\Delta f\geq {\frac {E}{\pi }}
  \label{eq:uncertainity}
\end{equation}
Равенство $\Delta t\Delta f={\frac {E}{\pi }}$ достигается только в случае гауссова импульса $x(t)=Ce^{-kt^{2}}$, где 
$k$ и $C$ - некоторые константы ($k>0$). \cite{Umnyashkin}

Это отношение применимо и к оконным функциям, и к вейвлетам, которые являются базисом для разложения. 
В контексте спектрограммы принцип неопределенности проявится в размытии образа сигналов на соседние частоты и времена с шириной $\Delta t$ и $\Delta f$.
Иллюстрацию этого явления можно увидеть на рисунке \ref{fig:windows}

Рассмотрим подробно окно в виде гауссовской функции. Его спектр представлен также гауссовской функцией. Хоть она и является инфинитной (не равна нулю на всей шкале времени),
но приближается к нулю с экспоненциальной скоростью. Хотя финитный сигнал не может иметь финитный спектр, 
такое окно вполне удовлетворяет практическим сценариям применения и имеет понятный физичиский смысл - локализация события имеет нормальное распределение.
Как было показано, Гауссовское окно обладает наилучшими характеристиками для локализации событий одновременно в частотной и во временной области.
Это окно используется в преобразовании Габора \cite{Gabor} (STFT с гауссовским окном) и вейвлетах Морле \cite{MorleWavelet}.

Кроме того, при использовании гауссовского окна в прямом и обратном преобразовании, искажения, наложеннные на спектрограмму в одном месте, наложат сильно ограниченные по времени и частоте изменения в сигнал 
(преобразование является линейным, поэтому его след в частотно-временном представлении будет результатом свертки окна с искажением), 
что придает обратному преобразованию большую устойчивость к искажениям, чем при использовании любого другого окна. 
Поэтому в данной работе предлагается использование именно гауссовского окна.

\subsection{Естественная для человеческого слуха шкала амплитуд и частот}
Используемые в задачах синтеза речи способы представления аудиосигнала, такие как мел-спектрограмма, опираются на исследования восприятия человеком звука, 
его чувствительности к громкости и тональности звуков. 

Для задач генерации звука с помощью нейросетей важно построить шкалу, 
на которой изменение частоты $\Delta f$ или амплитуды $\Delta a$ будет одинаково ощущаться человеком при любом абсолютном значении частоты или амплитуды.
Это связано с тем, что при обучении нейросети возникают погрешности, ограниченные снизу в зависимости от learning rate. 
Обучение нейросети представляет собой минимизацию ошибки. 
И если лосс-функция одинаково чувствительна к ошибке на всем диапазоне значений, то обучение идет более равномерно и стабильно, и приводит к лучшим результатам,
чем когда чувстительность лосс-функции сильно различается в зависимости от абсолютного значения.
При правильной постановке задачи обучения чувствительность лосс-функции к ошибке нейросети должна быть пропроциональна чувствительности человечекого слуха к этой ошибке. 
Поэтому, если в выходном представлении частоты и амплитуды будут расположены на шкале, на которой изменения в любом диапазоне ощущаются человеком одинаково, 
нейросеть сможет достичь лучшего качества синтезируемого звука.

Естественной для человеческого восприятия \textbf{шкалой громкости} звука является логарифмическая шкала или \textbf{децибелы}.
Еще в 19 веке было установлено, что характер отображения в органах чувств человека и животных изменений течения многих физических и 
биологических процессов пропорционален логарифму интенсивности раздражителя (эмипрический Закон Вебера — Фехнера).
Эта особенность делает применение логарифмических шкал, логарифмических величин и их единиц вполне естественным.
Многочисленные исследования показывают, что это относится и к восприятию громкости звука.

Теперь разберемся, что же означает громкость звука в децибелах. 
Если громкость звука (субъективно определяемая его интенсивностью) возросла на 10 дБ, то это значит, что интенсивность звука возросла в 10 раз.
Это можно выразить формулой:
\begin{equation}
  dB(I) = 10 * lg(\frac{I}{I_0})
\end{equation}
Отметим, что коэффициент 10 справедлив для энергетических величин. 
Если измеряется отношение силовых величин (амплитуда, звуковое давление), то интенсивность (энергетическая величина) пропорциональна их квадрату. 
Поэтому перед логарифмом нужно использовать коэффициент 20, чтобы получить такое же изменение, как и при логарифмировании энергетической величины.

Использование децибелов при указании громкости звука обусловлено человеческой способностью воспринимать звук в очень большом диапазоне изменений его интенсивности. 
Применение линейной шкалы оказывается практически неудобным. Кроме того, на основании закона Вебера — Фехнера, 
ощущение громкости звука пропорционально логарифму его интенсивности. Отсюда удобство логарифмической шкалы. 
Диапазон величин звукового давления от минимального порога слышимости звука человеком (20 мкПа) до максимального, 
вызывающего болевые ощущения, составляет примерно 120 дБ. 
Например, утверждение «громкость звука составляет 30 дБ» означает, что интенсивность звука в 1000 раз превышает порог слышимости звука человеком.
Для выражения громкости звука также используют единицы фон и сон, учитывающие частотную и субъективную восприимчивость звука человеком.

Стоит также уделить внимание наличию порога слышимости. Человек не может различать уровни громкости вблизи порога слышимости так же хорошо, 
как в привычном диапазоне. А если громкости двух звуков ниже этого порога, то в нужной нам естественной шкале они должны быть практически равны нулю.
Этого можно добиться, если в стандартную формулу децибела добавить слагаемое $1 +$ под логарифмом. 
В результате получим такую формулу перевода шкалы громкости для спектрограммы из интенсивности в децибелы.
\begin{equation}
  I_{db}[m, k] = 10 lg(1 + \frac{I[m, k]}{I_0}),
\end{equation}
где $I_0$ - интенсивность порога слышимости, определяется эмпирически. Интенсивность звука на спектрограмме $I[m,k]$ получается как 
квадрат модуля спектральной компоненты $\mathrm{spec}[m,k]$, поскольку спектр получен с помощью линейного преобразования от сигнала 
$x(t)$ - звукового давления микрофона от времени.

Стоит также осветить вопрос зависимости энергии звуковой волны от частоты. Поскольку в колебаниях и волнах энергия перетекает между потенциальной и кинетической,
полная энергия колебаний равна либо максимальной потенциальной, либо максимальной кинетической. 
Максимальная кинетическая энергия пропорциональна квадрату амплитуды скорости: $E \sim \dot{x}_0^2$. 
В синусоидальных колебаниях и волнах амплитуда скорости на заданной частоте пропорциональна амплитуде смещения, 
умноженной на частоту: $\dot{x}_0 = x_0 \cdot \omega = x_0 \cdot 2\pi f$. 
Отсюда, энергия колебаний $E \sim (x_0 \cdot f)^2$.

Если в аудиозаписи человеческого разговора посчитать для каждой частоты среднюю амплитуду смещения и среднюю амплитуду скорости (Рисунок \ref{fig:spectrum_mean}), 
можно увидеть, что амплитуда скорости распределена почти равномерно по частотам. Это означает, что человек при разговоре производит звук, 
энергия которого распределена по частотам почти равномерно. Поэтому следует ожидать, 
что и чувствительность слуха к изменению энергии (а значит и апмлитуды скорости) будет почти одинакова на разных частотах.

\begin{figure}
  \centering
  \includegraphics[width=0.9\linewidth]{figures/spectrum_mean}
  \caption{Средние амплитуды смещения и скорости на разных частотах в аудиосигнале}
  \label{fig:spectrum_mean}
\end{figure}


Теперь рассмотрим используемые в технике и акустике \textbf{шкалы частот}:

\textbf{Линейная} шкала используется в обратимых алгоритмах разложения сигнала, а также в системах передачи многоканальных данных по радиосвязи или в одном сигнале.
  
\textbf{Логарифмическая} шкала используется в музыке, в нотной системе (соседние ноты отличаются на $\sqrt[12]{2}$). 
Логарифмическое представление хорошо отражает чувствительность человеческого слуха к частоте, что и было положено в основу системы нот и подтверждается многими исследованиями.
Кроме того, у логарифмической шкалы есть полезное свойство - гармоники $f_n = n * f_0$ произвольной частоты $f_0$ будут расположены на 
фиксированном расстоянии от основной частоты на логарифмической шкале:
$log(f_n) - log(f_0) = log(n)$. В природе множество звуков издается стоячими волнами в резонаторах, которые излучают несколько гармоник, в том числе и человеческий голос.
И на логарифмической шкале спектрограммы двух звуков, созданных таким резонатором (гитара, флейта, голос), с разными опорными частотами, 
будут сдвинуты по шкале частот с сохранением расстояний между гармониками (но амплитуды каждой гармоники могут измениться). 
К проблемам логарифмической шкалы можно отнести то, что у человека существует верхний и нижний порог чувствительности частоты, 
за которыми начинаются ультразвук и инфразвук, не слышимые человеком. 
Логарифмическая шкала не учитывает изменения в чувствительности вблизи порогов слышимости.

\textbf{Мел-шкала} \cite{MelScale} частот основана на исследованиях о чувствительности человеческого слуха к изменению частоты. Название связано со словом "мелодия".
Частота по этой шкале измеряется в мелах. Расстояние между соседними частотами в 1 мел означает, что они едва различимы человеком.
Эмпирическая формула (О'Шонесси, 1987 \cite{oshaughnessy1987speech}) для перевода из $f$-герц в $m$-мелы выглядит так:
\begin{equation}
  m = 2595 \log_{10}(1 + \frac{f}{700}) = 1127 \ln(1 + \frac{f}{700})
\end{equation}


Теперь рассмотрим вопрос выбора ширины окна в зависимости от частоты и шкалы частот. 
Каждый элемент спектрограммы соответствует координате на плоскости частота-время $(f, t)$. Все координаты вместе образуют некую сетку, 
заполняющую частотно-временное пространство сигнала. 
Каждый элемент получается путем свертки сигнала с вейвлетом частоты $f$, расположенным во времени вокрут точки $t$.  
Исходя из формы окна вейвлета и соотношения неопределенности \ref{eq:uncertainity} для преобразования Фурье, 
эта свертка с вейвлетом позоляет захватывать временную область сигнала шириной $\Delta t$ и частотную область сигнала шириной $\Delta f$, 
которые связаны между собой соотношением неопределенности $\Delta t \Delta f = const \geq {\frac {E}{\pi }}$. Значение константы зависит от формы окна.

В линейной шкале все базисные элементы расположены равноудаленно по времени и частоте. 
Поэтому в линейной шкале одинаковый размер окна для любой частоты позволяет захватывать всю частотную область.
Выбрав окно с шириной спектра $\Delta f = f_{max} / N$, и подобрав шаг
по времени $\leq \Delta t$, можно покрыть полностью всё частотно-временное пространство сигнала.

\begin{wrapfigure}{r}{0.3\textwidth}
  \includegraphics[width=0.9\linewidth]{figures/windows_mel}
  \caption{Одинаковая и переменная ширина окна в мел-шкале}
  \label{fig:windows_mel}
\end{wrapfigure}

Однако, в нелинейной шкале, такой как логарифмическая или мел-шкала, расстояния между соседними частотами различаются. 
Если в некоторой области частот ширина окна $\Delta f$ будет меньше разницы частот между соседними элементами спектрограммы (см. Рисунок \ref{fig:windows_mel}, слева),
то часть информации о сигнале будет утеряна, что сделает невозможным его точное восстановление.
Если же ширина окна $\Delta f$ будет больше разницы частот между соседними элементами спектрограммы, 
элементы будут накладываться друг на друга и перемешиваться,
что выражается в снижении эффективного разрешения спектрограммы по частоте.
При выборе для каждой опорной частоты $f$ своей спектральной ширины окна $\Delta f(f)$, пропорциональной расстоянию между соседними частотами на выбранной шкале, 
удается добиться оптимального разрешения по частоте и сохранить всю частотную информацию сигнала (см. Рисунок \ref{fig:windows_mel}, справа). 
Ширина окна по времени $\Delta t(f) = C / \Delta f(f)$ выбирается исходя из соотношения неопределенности.

С другой стороны, при таком выборе размеров окна, ширина $\Delta t(f)$ на высоких частотах может стать меньше шага сетки, что приведет к потере информации.
На низких частотах, где $\Delta t$ больше шага сетки, наоборот возникает наложение сигнала по времени, что приводит к избыточности информации в спектрограмме. 
Как мы увидим далее, такая избыточность не помешает восстановлению информации.


\subsection{Восстановление сигнала}
В данном разделе рассмотрим алгоритмы восстановления аудиосигнала из спектрограммы.

Если спектрограмма была построена с помощью оконного преобразования Фурье (STFT, Равенство \ref{eq:stft}), то для восстановления сигнала можно воспользоваться обратимостью ДПФ.
Для каждой координаты $m$ по времени можем получить фрагмент сигнала $x[n]$, умноженный на окно $w[n-m]$ в окрестности координаты $m$: 

\begin{equation}
  x_m[n] = \textbf{IDFT}\{spec[m](k)\}(n) = x[n]*w[n - m]
  \label{eq:idft}
\end{equation}

Останется правильным образом выполнить сшивку фрагментов сигнала, умноженных на окно, в единый сигнал.
Элемент сигнала $x[n]$ можно представить как взвешенную сумму

\begin{equation}
  x[n] = \frac{\sum_{m_i} x[n]*w[n-m_i]}{\sum_{m_i} w[n-m_i]}
\end{equation}

\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{figures/windows_sum}
  \caption{Окна с шагом как коэффициенты взвешенной суммы}
  \label{fig:windows_sum}
\end{figure}

Если посчитать заранее сумму всех окон $w_{sum}$ (\ref{eq:wsum}), то исходный сигнал $x[n]$ можно будет получить, 
просуммировав все сигналы $x_{m_i}[n]$ и разделив на $w_{sum}[n]$ (см. \ref{eq:istft_final})

\begin{equation}
  w_{sum}[n] = \sum_{m_i} w[n-m_i]
  \label{eq:wsum}
\end{equation}

\begin{equation}
  x[n] = \frac{\sum_{m_i} x_{m_i}[n]}{w_{sum}[n]} 
  \label{eq:istft_final}
\end{equation}


Для построения спектрограммы также можно использовать вейвлет-преобразование \cite{mallat2008wavelet}, 
которое строится на основе сверток вейвлет-функции $\psi(t)$ с сигналом $x(t)$.

Для осуществления и обратимости вейвлет-преобразования, вейвлет-функции должны удовлетворять следующим критериям:

Вейвлет $\psi(t)$ должен обладать конечной энергией: 
\begin{equation}
  E=\int \limits _{-\infty }^{\infty }{|\psi (t)|}^{2}\,dt<\infty
\end{equation}

Если ${\hat{\psi }}(f)$ - фурье-преобразование для вейвлета $\psi (t)$, то должно выполняться следующее условие:
\begin{equation}
  C_{\psi }=\int \limits _{0}^{\infty }{\frac {{|{\hat {\psi }}(f)|}^{2}}{f}}\,df<\infty
\end{equation}
Это условие называется условием допустимости (admissibility). Из него следует, что вейвлет должен иметь нулевое среднее 
(т.е. $\int_{-\infty}^{\infty}{\psi(t)}\,dt = 0$) и не должен содержать компоненту на нулевой частоте (${\hat{\psi }}(0) = 0$)

\textbf{Непрерывное вейвлет-преобразование} (CWT) \cite{mallat2008wavelet} определяется следующим образом:
\begin{equation}
  T(a,b)={\frac {1}{\sqrt {a}}}\int \limits _{-\infty }^{\infty }x(t)\psi ^{*}\left({\frac {t-b}{a}}\right)\,dt
\end{equation}
где ${\psi }^{*}$ означает комплексное сопряжение для $\psi$, параметр $b\in R$ соответствует временному сдвигу, и называется параметром положения, 
параметр $a>0$ задает масштабирование и называется параметром растяжения. 

Исходный сигнал может быть восстановлен по формуле обратного преобразования
\begin{equation}
  x(t)={\frac {1}{C_{\psi }}}\int \limits _{-\infty }^{\infty }\int \limits _{-\infty }^{\infty }T(a,b)\,{\psi }_{a,b}(t)\,da\,db}
\end{equation}

В дискретном случае, параметры масштабирования a и сдвига b представлены дискретными величинами: $a=a_{0}^{m},\quad b=nb_{0},\quad$где $m$ и $n$ — целые числа.

Тогда анализирующий вейвлет имеет следующий вид:
\begin{equation}
  \psi _{m,n}=a_{0}^{-m/2}\psi \left({\frac {t-nb_{0}}{a_{0}^{m}}}\right)
\end{equation}

В таком случае для непрерывного сигнала $x(t)$ дискретное вейвлет-преобразование и его обратное преобразование запишутся следующими формулами:
\begin{equation}
  {\displaystyle T_{m,n}=\int \limits _{-\infty }^{\infty }x(t)\,\psi _{m,n}^{*}(t)\,dt}
\end{equation}
Величины $T_{m,n}$ также известны как вейвлет-коэффициенты.
\begin{equation}
  x(t)=K_{\psi }\sum \limits _{m=-\infty }^{\infty }\sum \limits _{n=-\infty }^{\infty }T_{m,n}\psi _{m,n}(t)
\end{equation}
где $K_{\psi }$ — постоянная нормировки.

В данной работе применяется алгоритм, который во многом схож с дискретным вейвлет-преобразованием, но все же его точная формула отличается.


В результате как оконного преобразования Фурье, так и вейвлет-преобразования, получается набор комплексных коэффициентов $T_{m,n} \in \mathbb{C}$. 
Такое представление имеет амплитудную и фазовую составляющую (см. Рисунок \ref{fig:complex_spec}). 

\begin{figure}
  \centering
  \includegraphics[width=0.9\linewidth]{figures/complex_spec}
  \caption{Комплексное представление спектрограммы}
  \label{fig:complex_spec}
\end{figure}

Фазовая составляющая может быть менее предсказуемой для нейросетей, чем амплитудная.
Поэтому на практике, как для анализа звука, так и для синтеза, чаще используют только амплитудную часть спектрограммы, отбрасывая фазовую.
Однако, это не обязательно, можно обучать нейросеть синтезировать полное комплексное представление (см. Раздел \ref{sec:sec_3_1}).


Существуют способы восстановить фазовую информацию в спектрограмме, в которой сохранена только амплитудная часть комплексного представления.
В случае, если спектрограмма построена в линейной шкале частот с помощью STFT, с этой задачей справляется алгоритм Гриффина-Лима \cite{1164317}.

Основной принцип работы алгоритма заключается в следующем: Пусть $x(t)$ - звуковой сигнал, тогда 
\begin{equation}
X(t, f) = \int_{-\infty}^\infty x(\tau) w(\tau - t) e^{-2\pi i f \tau} d\tau
\end{equation}
 -- его спектрограмма, построенная с помощью оконного преобразования Фурье.
Отбрасывая фазовую часть и сохраняя только амплитудную часть, получим действительнозначную спектрограмму $X_0(t, f) = |X(t, f)|$.

В оригинальной статье \cite{1164317} был описан и обоснован итеративный алгоритм, который позволяет восстановить исходную спектрограмму 
с фазовой информацией с заданной точностью при достаточном количестве итераций. Каждая итерация алгоритма выглядит следующим образом:

\begin{equation}
  \tilde{x}_{i+1}(t) = \textbf{ISTFT}\{X_i(t, f)\}
  \label{eq:griffin_lim_1}
\end{equation}
\begin{equation}
  \tilde{X}_{i+1} = \textbf{STFT}\{\tilde{x}_{i+1}(t)\}
  \label{eq:griffin_lim_2}
\end{equation}
\begin{equation}
  X_{i+1}(t, f) = X_0(t, f) * e^{i\,\arg(\tilde{X}_{i+1})}
  \label{eq:griffin_lim_3}
\end{equation}

На начальной итерации в качестве входной спектрограммы $X_i(t, f)$ используется $X_0(t, f) = |X(t, f)|$. 
Первое и второе ревенства \ref{eq:griffin_lim_1},\ref{eq:griffin_lim_2} означают применение обратного STFT к спектрограмме 
и последующее построение спектрограммы полученного сигнала с помощью STFT. 
В результате у спектрограммы $\tilde{X}_{i+1}$ корректируется фазовая часть, приближаясь к исходной, но изменяется амплитудная часть.
Третье равенство \ref{eq:griffin_lim_3} означает получение спектрограммы $X_{i+1}(t, f)$ с амплитудной частью от $X_0(t, f)$, а фазовой частью от $\tilde{X}_{i+1}$.
В итоге спектрограмма $X_{i+1}(t, f)$ сходится к исходной $X(t, f)$

Если к спектрограмме не были применены трансформации или наложены искажения, алгоритм способен восстановить исходный сигнал с любой заданной точностью.
Но на практике в сочетании с нейросетевыми генераторами спектрограмм, которые не воссоздают полностью всю информацию в спектрограмме, 
алгоритм приводит к появлению нежелательных звуковых искажений, 
таких как эхо, вибрирующие паразитные звуки, дребезг. 


\section{Устойчивость к трансформациям и артефактам}

В данном разделе рассмотрим вопрос устойчивости вокодеров к трансформацим спектрограммы и артефактам, которые появляются в результате работы нейросетей.

В приложениях обработки звука и синтеза речи к спектрограммам могут применяться следующие трансформации:
\begin{itemize}
  \item \textbf{Растяжение/сжатие по времени} позволяет ускорить или замедлить речь, при этом сохраняя тональность голоса. Также может использоваться для сжатия информации.
  \item \textbf{Перемещение по шкале частот} (с возможной интерполяцией по новым частотам) позволяет корректировать тональность звука.
  \item \textbf{Вырезание/вставка} фрагмента. Желательно, чтобы данная процедура не создавала звуковых артефактов на краях области вставки. 
  Также стоит отметить, что вставляемый фрагмент сдвигается по времени, и если в спектрограмме заложена явная зависимость от времени в фазовой части, 
  на границах могут появиться нежелательные искажения.
  \item \textbf{Cуммирование сигналов} позволяет накладывать разные звуки друг на друга.
\end{itemize}
Устойчивость обратного преобразования к данным трансформациям расширяет возможности его использования в приложениях обработки звука.

При генерации спектрограммы нейросетью могут также возникать следующие артефакты:
\begin{itemize}
  \item \textbf{Паразитный аддитивный сигнал}, постоянный во времени на спектрограмме. 
  Проявляется этот эффект в добавлении тихого писка или "электрического" шума на фоне.
  Возникает, когда в обучающей выборке на какой-то частоте среднее значение амплитуды сильно отличается от уровня тишины, но при этом изменяется во всем диапазоне.
  Такой эффект возникает из-за того, что на ранних стадиях обучения нейросети выгодно для минимизации лосс-функции стянуть выходные значения к среднему 
  и предсказывать отклонения относительно среднего. Чаще всего эффект сохраняется и на поздних стадиях.
  \item \textbf{Сглаживание шума и пиков} возникает опять же из-за того, что для минимизации лосс-функции выгодно стянуть значения к локальному среднему.
  Шумы представлены на спектрограмме реализацией нормального распределения амплитуды с некоторым средним $\mu(t,f)$ и стандартным отклонением $\sigma(t,f)$, изменяющимся по времени и частоте.
  Полная реализация шума несет в себе намного больше информации, чем его среднее $\mu(t,f)$, и обычно нейросети сохраняют только среднее. 
  В результате появляется эффект сглаживания шумов. После восстановления сигнала этот эффект проявляется в том, что вместо шипящих и шумящих звуков (глухие согласные, шепот)
  слышится звонкий дребезжащий звук. 
  \item \textbf{Потеря информации при конвертации} шкалы частот или частоты семплирования. 
  Нейросети используют обычно мел-шкалу из-за эффективности распределения полезной информации по частотам, 
  но алгоритмы восстановления сигнала, такие как алгоритм Гриффина-Лима часто ограничены условием использования линейной шкалы частот. 
  \item \textbf{Потеря связанности независимых звуков}. При использовании оконной функции с широким спектром, 
  отдаленные частоты могут быть связаны друг с другом сложным образом, который нейросеть не способна сохранить. 
  В результате при смешении звуков, которые могут возникать независимо друг от друга, появляются неточности. 
  Поэтому желательно использовать окно с наилучшей локальностью как по времени, так и по частоте.
\end{itemize}
Для алгоритмического восстановления звука из спектрограммы, сгенерированной нейросетью, алгоритм должен быть устойчив к данным искажениям. 
Это означает, что качество звука, слышимое человеком, не должно снижаться после наложения на спектрограмму данных искажений.


\section{Выводы по главе 1}

На данном этапе развития технологий синтеза речи идет работа над улучшением качества синтезируемого звука. С одной стороны, модели учатся производить
более натурально звучащую речь за счет учета интонации, пауз, стиля речи и пр. С другой стороны, декодеры, преобразующие внутреннее представление в звук,
оттачиваются, и устраняются источники потери качества звука. 
Также актуально сокращение вычислительной сложности моделей и алгоритмов на всех этапах синтеза речи, что делает применение технологии более доступной и дешевой.

Актуален класс систем синтеза речи, использующий в качестве внутреннего представления спектрограмму. 
Декодер спектрограммы в аудиосигнал должен быть устойчив к ряду искажений для достижения наилучшего качества синтезируемого звука.
На сегодняшний день широко используются нейросетевые декодеры (например HiFi-Gan), 
которые способны восстанавливать звук из спектрограммы с хорошим качеством и устойчивы к искажениям. 
Однако, их использование требует вычислительных ресурсов, намного больших чем построение спектрограммы.

С другой стороны, существуют алгоритмы (например Гриффина-Лима), способные восcтанавливать звук с вычислительными затратами, сопоставимыми с построением спектрограммы (STFT),
но пока что не существует алгоритмического декодера, который был бы устойчив к искажениям, возникающим при генерации спектрограммы нейросетью, 
и поэтому использование алгоритмических декодеров пока что не позволяет достичь наилучшего качества звука.

Если бы существовал алгоритмический декодер спектрограммы, способный восстанавливать аудиосигнал с качеством, 
сопоставимым с современными нейросетевыми вокодерами, при этом устойчивый к искажениям во входных данных и обладающий более высокой скоростью работы, 
это могло бы упростить архитектуру TTS-систем, сократить вычислительные затраты и повысить доступность синтеза речи. 
Кроме того, использование стандартизированного формата спектрограмм позволило бы сосредоточить усилия на улучшении генератора, 
ускорить обучение и повысить воспроизводимость моделей.

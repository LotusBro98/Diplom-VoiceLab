\chapter{Обзор существующих подходов и теоретическая справка}
\label{cha:ch_1}


\section{Архитектуры нейронных сетей для синтеза речи}
Современные решения для преобразования текста в речь в основном устроены следующим образом: (cм. Рисунок \ref{fig:tts_pipeline})

\begin{enumerate}
    \item В начале текст токенизируется - преобразуется из строкового формата в последовательность лексем - токенов
    \item токенизированный текст преобразуется с помощью нейросети-энкодера во внутреннее признаковое представление
    \item используя текстовые признаки, нейросеть генерирует признаковое представление звука или спектрограмму. Этот модуль может быть многоуровненвым и сложным в зависимости от архитектуры.
    \item признакове представление звука декодируется в звуковой сигнал.
\end{enumerate}

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/tts_pipeline}
  \caption{Преобразование текста в речь}
  \label{fig:tts_pipeline}
\end{figure}

Также помимо задачи преобразования текста в речь, существуют задачи замены голоса, генерации музыки, перевода с сохранением голоса и прочие.
Их пайплайн устроен похожим образом, но какие-то части могут отличаться. 
Отметим, что в любой из перечисленных задач неотъемлемой частью пайплайна является этап декодирования звука из признакового представления в аудиосигнал.




\subsection{Понятие спектрограммы}
Прежде чем продолжить рассмотрение современных подходов для синтеза речи, раскроем понятие спектрограммы.

\textbf{Спектрограмма} - это двумерный массив данных, представляющий из себя разложение сигнала по спектру, изменяющееся во времени.
Такое разложение можно получить например с помощью оконного преобразования Фурье или вейвлет-преобразования. 
По горизонитальной оси отложено время в линейной шкале. По вертикальной оси отложены частоты, в некоторой шкале, не обязательно линейной.
На практике используются линейная, логарифмическая и мел-шкала.
\begin{itemize}
  \item Линейная шкала используется обычно в обратимых алгоритмоах или как разложение для передачи многоканальной информации в одном сигнале.
  \item Логарифмическая шкала используется в музкальных приложениях и редакторах.
  \item мел-шкала используется для анализа голоса. Она построена на исследованиях чувствительности человеческого слуха к изменению частоты.
\end{itemize}

На рисунке \ref{fig:log_spec} изображен пример спектрограммы в логарифмической шкале, а на рисунке \ref{fig:mel_spec} - в мел-шкале.
\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/log_spec}
  \caption{Спектрограмма записи игры на металлофоне в логарифмической шкале частот с указанием нот}
  \label{fig:log_spec}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/mel_spec}
  \caption{Спектрограмма записи голоса в мел-шкале}
  \label{fig:mel_spec}
\end{figure}




\subsection{Классификация моделей}
Рассмотрим основные подходы, использующиеся в современных решениях синтеза речи и их классификацию.


\subsubsection{По формату промежуточного представления}
По формату промежуточного представления методы делятся на несколько типов:

\textbf{Генераторы спектрограмм} подразумевают генерацию спектрограммы с последующим преобразованием спектрограммы в звуковой сигнал. Примеры таких моделей:
\begin{itemize}
  \item Tacotron 2 (Google, 2017) \cite{Tacotron2} - классическая модель, использующая последовательное преобразование текста в мел-спектрограмму, с последующим применением вокодера для декодирвоания звука.
  \item FastSpeech 2 (Microsoft, 2019–2020) \cite{FastSpeech2} - Ускоренные и более стабильные версии Tacotron.
  \item Riffusion (2022) \cite{Riffusion} - Диффузионная модель, генерирующая песни и инструментальную музыку в виде спектрограмм с последующим декодированием в звук.
  \item TalkNet (2020, NVIDIA) \cite{TalkNet} - Полносверточная text-to-speech модель
\end{itemize}

\textbf{Генераторы в латентное представление} с последующим декодированием в звук с помощью нейронного декодера подразумевают 
генерацию латентного признакого представления, чем-то отдаленно схожего со спектрограммой, но сформированного отдельно обученным автоэнкодером.

\begin{itemize} 
  \item NaturalSpeech 2 (Microsoft, 2023) \cite{NaturalSpeech2} - Современная модель на основе латентных диффузий для синтеза речи и пения
  \item Kokoro-TTS (2025) \cite{kokoro}- это современная, компактная и высокоэффективная модель синтеза речи, разработанная для генерации естественного звучания при минимальных вычислительных затратах
\end{itemize}

\textbf{Генераторы токенов для нейронного кодека} схожи по принципу работы с генеративными трансформерами - основная генеративная модель создает последовательность токенов, 
которая потом преобразуется в звук с помощью нейросетевого кодека.

Пример такого кодека - EnCodec (Meta AI, 2022) \cite{encodec}. Он предназначен для сжатия и восстановления аудиосигналов, кодирует звук в дискретное латентное пространство (токены).

\begin{itemize} 
  \item Bark (Suno AI) \cite{SunoAI_Bark_2023} - Трансформерная генеративная модель, синтезирующая музыку и песни по заданному тексту и указаниям.
  \item Voicebox (2023, Meta AI) \cite{le2023voicebox} - Модель, способная генерировать, изменять и редактировать речь в различных стилях.
  \item VALL-E (Microsoft, 2023) \cite{Valle} - генерация речи с имитацией голоса на основе аудиопримера, на базе условной языковой модели.
\end{itemize}

\textbf{Одностадийные end-to-end аудиогенераторы} синтезируют звук напрямую, минуя стадию спектрограммы или отдельного декодера из латентного пространства.

\begin{itemize} 
  \item WaveNet (DeepMind, 2016) \cite{WaveNet} - Первая модель, которая напрямую генерировала звук по аудиосэмплам. Медленная, так как работает сэмпл за сэмплом (для аудио с частотой дискретизации 24 000 Гц — таких генераций должно быть 24 тысячи в секунду).
  \item DiffWave (Google, 2020) \cite{DiffWave} - Диффузионная модель, которая работает не со спектрограммой, а напрямую с аудиоволной. Высокое качество, но относительно медленная генерация.
\end{itemize}



\subsubsection{По принципу генерации промежуточного представления}
Если рассматривать принцип генерации промежуточного представления, то наиболее успешными являются трансформерные и диффузионные модели.
Также можно выделить полносверточные модели для обработки/восстановления звука, хотя существуют и полносверточные text-to-speech модели.


\textbf{Трансформерные генераторы} используют в качестве \textit{генератора} звукового представления GPT-подобный трансформер.
\begin{itemize}
  \item FastSpeech 2 (Microsoft, 2019–2020) \cite{FastSpeech2}
  \item Voicebox (2023, Meta AI) \cite{le2023voicebox}
  \item Bark (Suno AI) \cite{SunoAI_Bark_2023}
  \item Kokoro-TTS (2025) \cite{kokoro} - Поддерживает трансформеры в генераторе (настраиваемо)
  \item VALL-E (Microsoft, 2023) \cite{Valle} - генерация речи с имитацией голоса на основе аудиопримера, на базе условной языковой модели.
\end{itemize}

\textbf{Диффузионные генераторы} генерируют представление звука с помощью процесса обратной диффузии.
\begin{itemize}
  \item DiffWave (Google, 2020) \cite{DiffWave}
  \item NaturalSpeech 2 (Microsoft, 2023) \cite{NaturalSpeech2}
  \item Riffusion (2022) \cite{Riffusion}
\end{itemize}

\textbf{Полносверточные модели}
\begin{itemize} 
  \item TalkNet (2020, NVIDIA) \cite{TalkNet} - Полносверточная text-to-speech модель. В ней присутствуют отдельные полносверточные модели для предсказания длительности каждого текстового токена и модель для генерации спектрограмм. Очень быстрое обучение и синтез.
  \item Kokoro-TTS \cite{kokoro} в некоторых конфигурациях также может использовать полносверточный генератор с предсказанием длительности токенов, вместо трансформера.
  \item VoiceFixer (2022) \cite{VoiceFixer} - Восстановление повреждённой речи (например, из телефона, старых записей)
\end{itemize}


\section{Cуществующие вокодеры}
Среди существующих вокодеров, применяемых в современных системах синтеза речи, можно выделить следующие группы.

\textbf{Нейросетевые декодеры из спектрограммы} - HiFi-Gan \cite{hifigan}, WaveGlow \cite{WaveGlow} - восстанавливают звук из mel-спектрограммы
при помощи сверточных генеративных сетей. Информация в mel-спектрограмме может быть не полной или слегка искаженной, 
нейросеть все равно будет способна восстанавливать звук хорошего качества.

\textbf{Специализированные автоэнкодеры} - Сверточные сети, обученные под конкретную модель генератора. Так же способны генерировать звук хорошего качества, 
при этом часто работают быстрее, чем спектрограммные нейросетевые декодеры. Однако, под конкретную задачу и модель чаще всего требуется обучать отдельный 
автоэнкодер на большом объеме данных.

\textbf{Нейросетевые кодеки в дискретное латентное пространство} - EnCodec \cite{encodec} - кодирует звук в последовательность токенов. 
Может достигать хорошего качества в сочетании с трансформерами, и работает относительно быстро. Однако, в приложениях с большим разнообразием звуков и интонаций 
наблюдаются проблемы с качеством. А также этот кодек не работает с диффузионными и полносверточными генераторами.

\textbf{Алгоритмические декодеры из спектрограмм} - GriffinLim \cite{1164317} - Восстанавливает звук из спектрограммы (только магнитуды) в линейной шкале. 
Этот и другие алгоритмические декодеры могут восстанавливать звук точно без потерь. Но к сожалению при наложении небольших искажений,
пристуствующих в спектрограммах, сгенерированных нейросетью, появляются сильно заметные нежелательные артефакты (металлический звук, эхо), 
что делает такие декодеры неприменимыми в современных решениях. С другой стороны, такие декодеры заметно быстрее, чем нейросетевые, 
и могут быть использованы в приложениях для встраиваемых устройств с низкой вычислительной мощностью, когда можно пожертвовать качеством.


\subsection{Успехи и открытые проблемы}
Изучая успех упомянутых моделей среди сообщества и сравнивая качество синтезированного звука, можно сделать следующие выводы об успешности применения определенных технологий:

1. Существуют несколько технологий генерации звукового представления (диффузионные, трансформерные, полносверточные), способные синтезировать речь очень хорошего качества. Но такие технологии требуют больших вычислительных затрат. 
Есть оптимизированные решения, такие как Kokoro-TTS, достигающие высокого качества и высокой скорости работы за счет оптимизации архитектуры и размеров моделей, тщательной проработки и аккуратного обучения каждого компонента. 
Однако, у каждой технологии есть свои преимущества и недостатки, делающие ее более или менее пригодной для конкретной задачи.
Например: синтез музыки с множеством требований и указаний лучше всего удается диффузионным моделям. Полносверточные модели самые быстрые. 

2. Существует несколько типов вокодеров - использующие представление в виде спектрограммы, латентного представления, дискретного представления в виде токенов. Наилучшего качества в сочетании с нейросетями достигают нейросетевые вокодеры из латентного представления или спектрограммы. 
Алгоритмические вокодеры также существуют, но они неустойчивы к искажениям, которые неизбежно возникают при генерации представления с помощью нейросети, в результате чего появляются нежелательные артефакты.
Также для каждой технологии генерации подходит не любой тип промежуточного представления звука. Ниже рассмотрена совместимость технологий генерации с промежуточным представлением.

\begin{center}
\begin{tabular}{ c c c c }
                 & Спектрограмма & Латентное пр-е & Токены \\
    Диффузионные & +             & +              &        \\ 
  Трансформерные & +             & +              & +      \\  
 Полносверточные & +             & +              &     
\end{tabular}
\end{center}

Отсюда видно, что универсальными представлениями, работающими с любым типом генерации, являются спектрограмма и латентное векторное представление. 

3. Нейросетевой декодер из латентного пр-ва, обученный на одном наборе данных, 
может не подходить для применения на других данных (например на другом языке) или 
не подходить для конкретной задачи (учет интонации, акцента, персональности голоса говорящего).

4. Спектрограммные нейросетевые декодеры практически всегда требуют больших вычислительных затрат, чем из латентного пр-ва из-за избыточности информации. 
С другой стороны, в спектрограмме содержится достаточно информации для восстановления звука без потерь, 
и поэтому декодер из спектрограммы можно использовать для любой задачи, домена и технологии, и достигать наилучшего качества генерации.
Спектрограммное представление можно назвать \textit{универсальным} с точки зрения применимости технологии и задачи, но избыточным в плане вычислительных ресурсов 
(при использовании нейросетевого декодера).

5. Модели, генерирующие непосредственно звуковой сигнал, работают медленно и сложны в обучении. Практически всегда их можно разделить на две стадии - предобучение нейросетевого автоэнкодера в латентное пр-во и генерация на этом пр-ве.

6. Если бы существовал алгоритмический декодер спектрограммы, способный восстанавливать аудиосигнал с качеством, 
сопоставимым с современными нейросетевыми вокодерами, при этом устойчивый к искажениям во входных данных и обладающий более высокой скоростью работы на CPU, 
это могло бы упростить архитектуру TTS-систем, сократить вычислительные затраты и повысить доступность синтеза речи. 
Кроме того, использование стандартизированного формата спектрограмм позволило бы сосредоточить усилия на улучшении генератора, 
ускорить обучение и повысить воспроизводимость моделей.


\section{Спектральный анализ аудиосигналов}
В данном разделе рассмотрим теоретические основы алгоритмов построения спектрограмм и способы восстановления звукового сигнала из таких представлений.

Для начала рассмотрим \textbf{Оконное преобразование Фурье} или в англоязычной литературе Short-Time Fourier Transform (\textbf{STFT}) \cite{STFT}.

Оно представляет из себя двумерную функцию (от частоты и от времени), определяемую как преобразование Фурье от сигнала, умноженного на оконную функцию, сдвинутую во времени:

\begin{equation}
  \textbf{STFT}\{x(t)\} (\tau, \omega) = \int_{-\infty}^\infty x(t) w(t - \tau) e^{-i\omega t} dt
\end{equation}

Здесь \(w(t)\) - оконная функция. От ее выбора зависит разрешение спектрограммы по времени и по частоте. Иллюстрация работы STFT приведена на рисунке \ref{fig:mel_spec}.
В результате такого преобразования получается спектрограмма в линейной шкале, на которой можно увидеть, как разложение сигнала по частотам (спектр), изменяется во времени.

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/stft}
  \caption{Оконное преобразование Фурье (STFT)}
  \label{fig:stft}
\end{figure}

На практике используется дискретное оконное преобразование Фурье.
\begin{equation}
  \textbf{STFT}\{x[n]\} (m, k) = \sum_{n=0}^{N-1} x[n] w[n - m] e^{-2\pi i  \frac{k n}{N}} = \textbf{DFT}\{x[m:m+N] * w[0:N]\}(k)
  \label{eq:stft}
\end{equation}
Алгоритм его построения обычно следующий - из сигнала \(x[n]\) вырезается отрезок длиной \(N\) отсчетов со сдвигом по времени \(m\) отсчетов. 
Результат ДПФ выделенной части сигнала, умноженной на окно, присоединяется к массиву. В результате получается массив \([M \times K]\), 
представляющий из себя спектрограмму, как на рисунке \ref{fig:stft}

\begin{wrapfigure}{r}{0.4\textwidth}
  \includegraphics[width=0.9\linewidth]{figures/wavelet}
  \caption{Временное и спектральное представления вейвлета Морле \cite{MorleWavelet}}
  \label{fig:wavelet}
\end{wrapfigure}

Несложно показать, что преобразование является линейным, как и ДПФ.
Также можно представить каждый элемент $\textbf{STFT}\{x[n]\} (m, k)$ как свертку сигнала $x[n]$ с вейвлетом $w[n - m] e^{-2\pi i  \frac{k n}{N}}$.
И всю спектрограмму можно построить с помощью вейвлет-преобразования. Более того, для каждой частоты вейвлета можно выбирать свою ширину окна: 
$\psi_{k,m}(n) = w_k[n - m] e^{-2\pi i  \frac{k n}{N}}$. По такому принципу построено вейвлет-преобразование на основе вейвлета Морле \cite{MorleWavelet}, 
окном которого выбрана Гауссовская функция с шириной в несколько периодов соответствующей частоты. Это преобразование обратимо, так же как и STFT.

Рассмотрим влияние оконных функций на разрешение по времени и частоте. 
Оконная функция необходима для локализации события во временной области. 
Спектр оконной функции покажет, насколько хорошо событие локализовано в частотной области.
Кроме того, широкий спектр окна с паразитными "хвостами" создает связанность отдаленных частот. 
Небольшое искажение на одной частоте сильно влияет на другие частоты из-за таких эффектов, если не согласовано с этими частотами, 
чтобы в резульате интерференции получалось нужное значение. Примеры оконных функций и их спектров рассмотрены на рисунке \ref{fig:windows}

\begin{figure}[t]
  \centering
  \includegraphics[width=16cm]{figures/windows}
  \caption{Сравнение оконных функций}
  \label{fig:windows}
\end{figure}

По отношению к оконным функциям, а также любым сигналам, над которыми производится спектральное преобразование, сущетвует принцип неопределенности, который гласит, что
для дифференцируемых вещественных сигналов 
$x(t)$ с энергией $E$, для которых интеграл 
$t_{0} = \int \limits _{-\infty }^{\infty }tx^{2}(t)dt$ сходится и $\lim _{t\to \pm \infty }tx^{2}(t)=0$, произведение эффективной длительности сигнала 
$\Delta t$ и эффективной ширины полосы частот сигнала $\Delta f$ ограничено снизу \cite{Umnyashkin}:
\begin{equation}
  \Delta t\Delta f\geq {\frac {E}{\pi }}
  \label{eq:uncertainity}
\end{equation}
Равенство $\Delta t\Delta f={\frac {E}{\pi }}$ достигается только в случае гауссова импульса $x(t)=Ce^{-kt^{2}}$, где 
$k$ и $C$ - некоторые константы ($k>0$). \cite{Umnyashkin}

Это отношение применимо и к оконным функциям, и к вейвлетам, которые являются базисом для разложения. 
В контексте спектрограммы принцип неопределенности проявится в размытии образа сигналов на соседние частоты и времена с шириной $\Delta t$ и $\Delta f$.
Иллюстрацию этого явления можно увидеть на рисунке \ref{fig:windows}

Рассмотрим подробно окно в виде гауссовской функции. Его спектр представлен также гауссовской функцией. Хоть она и является инфинитной (не равна нулю на всей шкале времени),
но приближается к нулю с экспоненциальной скоростью. Хотя финитный сигнал не может иметь финитный спектр, 
такое окно вполне удовлетворяет практическим сценариям применения и имеет понятный физичиский смысл - локализация события имеет нормальное распределение.
Как было показано, Гауссовское окно обладает наилучшими характеристиками для локализации событий одновременно в частотной и во временной области.
Это окно используется в преобразовании Габора \cite{Gabor} (STFT с гауссовским окном) и вейвлетах Морле \cite{MorleWavelet}.

Кроме того, при использовании гауссовского окна в прямом и обратном преобразовании, искажения, наложеннные на спектрограмму в одном месте, наложат сильно ограниченные по времени и частоте изменения в сигнал 
(преобразование является линейным, поэтому его след в частотно-временном представлении будет результатом свертки окна с искажением), 
что придает обратному преобразованию большую устойчивость к искажениям, чем при использовании любого другого окна. 
Поэтому в данной работе предлагается использование именно гауссовского окна.

\subsection{Естественная для человеческого слуха шкала амплитуд и частот}
Используемые в задачах синтеза речи способы представления аудиосигнала, такие как мел-спектрограмма, опираются на исследования восприятия человеком звука, 
его чувствительности к громкости и тональности звуков. 

Для задач генерации звука с помощью нейросетей важно построить шкалу, 
на которой изменение частоты $\Delta f$ или амплитуды $\Delta a$ будет одинаково ощущаться человеком при любом абсолютном значении частоты или амплитуды.
Это связано с тем, что при обучении нейросети возникают погрешности, ограниченные снизу в зависимости от learning rate. 
Обучение нейросети представляет собой минимизацию ошибки. 
И если лосс-функция одинаково чувствительна к ошибке на всем диапазоне значений, то обучение идет более равномерно и стабильно, и приводит к лучшим результатам,
чем когда чувстительность лосс-функции сильно различается в зависимости от абсолютного значения.
При правильной постановке задачи обучения чувствительность лосс-функции к ошибке нейросети должна быть пропроциональна чувствительности человечекого слуха к этой ошибке. 
Поэтому, если в выходном представлении частоты и амплитуды будут расположены на шкале, на которой изменения в любом диапазоне ощущаются человеком одинаково, 
нейросеть сможет достичь лучшего качества синтезируемого звука.

Естественной для человеческого восприятия \textbf{шкалой громкости} звука является логарифмическая шкала или \textbf{децибелы}.
Еще в 19 веке было установлено, что характер отображения в органах чувств человека и животных изменений течения многих физических и 
биологических процессов пропорционален логарифму интенсивности раздражителя (эмипрический Закон Вебера — Фехнера).
Эта особенность делает применение логарифмических шкал, логарифмических величин и их единиц вполне естественным.
Многочисленные исследования показывают, что это относится и к восприятию громкости звука.

Теперь разберемся, что же означает громкость звука в децибелах. 
Если громкость звука (субъективно определяемая его интенсивностью) возросла на 10 дБ, то это значит, что интенсивность звука возросла в 10 раз.
Это можно выразить формулой:
\begin{equation}
  dB(I) = 10 * lg(\frac{I}{I_0})
\end{equation}
Отметим, что коэффициент 10 справедлив для энергетических величин. 
Если измеряется отношение силовых величин (амплитуда, звуковое давление), то интенсивность (энергетическая величина) пропорциональна их квадрату. 
Поэтому перед логарифмом нужно использовать коэффициент 20, чтобы получить такое же изменение, как и при логарифмировании энергетической величины.

Использование децибелов при указании громкости звука обусловлено человеческой способностью воспринимать звук в очень большом диапазоне изменений его интенсивности. 
Применение линейной шкалы оказывается практически неудобным. Кроме того, на основании закона Вебера — Фехнера, 
ощущение громкости звука пропорционально логарифму его интенсивности. Отсюда удобство логарифмической шкалы. 
Диапазон величин звукового давления от минимального порога слышимости звука человеком (20 мкПа) до максимального, 
вызывающего болевые ощущения, составляет примерно 120 дБ. 
Например, утверждение «громкость звука составляет 30 дБ» означает, что интенсивность звука в 1000 раз превышает порог слышимости звука человеком.
Для выражения громкости звука также используют единицы фон и сон, учитывающие частотную и субъективную восприимчивость звука человеком.

Стоит также уделить внимание наличию порога слышимости. Человек не может различать уровни громкости вблизи порога слышимости так же хорошо, 
как в привычном диапазоне. А если громкости двух звуков ниже этого порога, то в нужной нам естественной шкале они должны быть практически равны нулю.
Этого можно добиться, если в стандартную формулу децибела добавить слагаемое $1 +$ под логарифмом. 
В результате получим такую формулу перевода шкалы громкости для спектрограммы из интенсивности в децибелы.
\begin{equation}
  I_{db}[m, k] = 10 lg(1 + \frac{I[m, k]}{I_0}),
\end{equation}
где $I_0$ - интенсивность порога слышимости, определяется эмпирически. Интенсивность звука на спектрограмме $I[m,k]$ получается как 
квадрат модуля спектральной компоненты $\mathrm{spec}[m,k]$, поскольку спектр получен с помощью линейного преобразования от сигнала 
$x(t)$ - звукового давления микрофона от времени.


Теперь рассмотрим используемые в технике и акустике \textbf{шкалы частот}:

\textbf{Линейная} шкала используется в обратимых алгоритмах разложения сигнала, а также в системах передачи многоканальных данных по радиосвязи или в одном сигнале.
  
\textbf{Логарифмическая} шкала используется в музыке, в нотной системе (соседние ноты отличаются на $\sqrt[12]{2}$). 
Логарифмическое представление хорошо отражает чувствительность человеческого слуха к частоте, что и было положено в основу системы нот и подтверждается многими исследованиями.
Кроме того, у логарифмической шкалы есть полезное свойство - гармоники $f_n = n * f_0$ произвольной частоты $f_0$ будут расположены на 
фиксированном расстоянии от основной частоты на логарифмической шкале:
$log(f_n) - log(f_0) = log(n)$. В природе множество звуков издается стоячими волнами в резонаторах, которые излучают несколько гармоник, в том числе и человеческий голос.
И на логарифмической шкале спектрограммы двух звуков, созданных таким резонатором (гитара, флейта, голос), с разными опорными частотами, 
будут сдвинуты по шкале частот с сохранением расстояний между гармониками (но амплитуды каждой гармоники могут измениться). 
К проблемам логарифмической шкалы можно отнести то, что у человека существует верхний и нижний порог чувствительности частоты, 
за которыми начинаются ультразвук и инфразвук, не слышимые человеком. 
Логарифмическая шкала не учитывает изменения в чувствительности вблизи порогов слышимости.

\textbf{Мел-шкала} \cite{MelScale} частот основана на исследованиях о чувствительности человеческого слуха к изменению частоты. Название связано со словом "мелодия".
Частота по этой шкале измеряется в мелах. Расстояние между соседними частотами в 1 мел означает, что они едва различимы человеком.
Эмпирическая формула (О'Шонесси, 1987 \cite{oshaughnessy1987speech}) для перевода из $f$-герц в $m$-мелы выглядит так:
\begin{equation}
  m = 2595 \log_{10}(1 + \frac{f}{700}) = 1127 \ln(1 + \frac{f}{700})
\end{equation}


Теперь рассмотрим вопрос выбора ширины окна в зависимости от частоты и шкалы частот. 
Каждый элемент спектрограммы соответствует координате на плоскости частота-время $(f, t)$. Все координаты вместе образуют некую сетку, 
заполняющую частотно-временное пространство сигнала. 
Каждый элемент получается путем свертки сигнала с вейвлетом частоты $f$, расположенным во времени вокрут точки $t$.  
Исходя из формы окна вейвлета и соотношения неопределенности \ref{eq:uncertainity} для преобразования Фурье, 
эта свертка с вейвлетом позоляет захватывать временную область сигнала шириной $\Delta t$ и частотную область сигнала шириной $\Delta f$, 
которые связаны между собой соотношением неопределенности $\Delta t \Delta f = const \geq {\frac {E}{\pi }}$. Значение константы зависит от формы окна.

В линейной шкале все базисные элементы расположены равноудаленно по времени и частоте. 
Поэтому в линейной шкале одинаковый размер окна для любой частоты позволяет захватывать всю частотную область.
Выбрав окно с шириной спектра $\Delta f = f_{max} / N$, и подобрав шаг
по времени $\leq \Delta t$, можно покрыть полностью всё частотно-временное пространство сигнала.

\begin{wrapfigure}{r}{0.3\textwidth}
  \includegraphics[width=0.9\linewidth]{figures/windows_mel}
  \caption{Одинаковая и переменная ширина окна в мел-шкале}
  \label{fig:windows_mel}
\end{wrapfigure}

Однако, в нелинейной шкале, такой как логарифмическая или мел-шкала, расстояния между соседними частотами различаются. 
Если в некоторой области частот ширина окна $\Delta f$ будет меньше разницы частот между соседними элементами спектрограммы (см. Рисунок \ref{fig:windows_mel}, слева),
то часть информации о сигнале будет утеряна, что сделает невозможным его точное восстановление.
Если же ширина окна $\Delta f$ будет больше разницы частот между соседними элементами спектрограммы, 
элементы будут накладываться друг на друга и перемешиваться,
что выражается в снижении эффективного разрешения спектрограммы по частоте.
При выборе для каждой опорной частоты $f$ своей спектральной ширины окна $\Delta f(f)$, пропорциональной расстоянию между соседними частотами на выбранной шкале, 
удается добиться оптимального разрешения по частоте и сохранить всю частотную информацию сигнала (см. Рисунок \ref{fig:windows_mel}, справа). 
Ширина окна по времени $\Delta t(f) = C / \Delta f(f)$ выбирается исходя из соотношения неопределенности.

С другой стороны, при таком выборе размеров окна, ширина $\Delta t(f)$ на высоких частотах может стать меньше шага сетки, что приведет к потере информации.
На низких частотах, где $\Delta t$ больше шага сетки, наоборот возникает наложение сигнала по времени, что приводит к избыточности информации в спектрограмме. 
Как мы увидим далее, такая избыточность не помешает восстановлению информации.


\subsection{Восстановление сигнала}
В данном разделе рассмотрим алгоритмы восстановления аудиосигнала из спектрограммы.

Если спектрограмма была построена с помощью оконного преобразования Фурье (STFT, Равенство \ref{eq:stft}), то для восстановления сигнала можно воспользоваться обратимостью ДПФ.
Для каждой координаты $m$ по времени можем получить фрагмент сигнала $x[n]$, умноженный на окно $w[n-m]$ в окрестности координаты $m$: 

\begin{equation}
  x_m[n] = \textbf{IDFT}\{spec[m](k)\}(n) = x[n]*w[n - m]
  \label{eq:idft}
\end{equation}

Останется правильным образом выполнить сшивку фрагментов сигнала, умноженных на окно, в единый сигнал.
Элемент сигнала $x[n]$ можно представить как взвешенную сумму

\begin{equation}
  x[n] = \frac{\sum_{m_i} x[n]*w[n-m_i]}{\sum_{m_i} w[n-m_i]}
\end{equation}

\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{figures/windows_sum}
  \caption{Окна с шагом как коэффициенты взвешенной суммы}
  \label{fig:windows_sum}
\end{figure}

Если посчитать заранее сумму всех окон $w_{sum}$ (\ref{eq:wsum}), то исходный сигнал $x[n]$ можно будет получить, 
просуммировав все сигналы $x_{m_i}[n]$ и разделив на $w_{sum}[n]$ (см. \ref{eq:istft_final})

\begin{equation}
  w_{sum}[n] = \sum_{m_i} w[n-m_i]
  \label{eq:wsum}
\end{equation}

\begin{equation}
  x[n] = \frac{\sum_{m_i} x_{m_i}[n]}{w_{sum}[n]} 
  \label{eq:istft_final}
\end{equation}





\begin{markdown}
- обратное вейвлет-преобразование
- Алгоритм Гриффина-Лима
    - как работает
\end{markdown}


\section{Устойчивость к трансформациям и артефактам}
\begin{markdown}
 - трансформации спектрограммы, устойчивость вокодера к трансформациям
   - растяжение\сжатие по времени
   - перемещение по шкале частот
   - вырезание\вставка куска
   - суммирование сигналов
 - от чего появляются трансформации и зачем нужны
 - артефакты от нейросетей
   - примеры полосок от сверток
   - BatchNorm паразитный bias
   - потеря шума
   - потеря outliers
 - устойчивость вокодеров к артефактам
 - инвариантность к сдвигу по времени, когда есть, зачем нужна
\end{markdown}


\section{Выводы по главе}
\begin{markdown}
 - борьба за качество генерации
 - как восстанавливать сигнал с нелинейной шкалой частот, когда нет ортогонального базиса
 - нет алгоритма, который был бы достаточно устойчив к артефактам от нейросетей
 - нейросетевые вокодеры:
   - требуют вычислительных ресурсов
   - нужно обучать на больших объемах данных
   - часто завязаны на домен, для другого домена могут хуже работать
 - избыточность представлений, тащим лишнюю информацию
 - нужна устойчивость обучения, глубокие сети сложнее учить
\end{markdown}


\chapter{Обзор существующих подходов и теоретическая справка}
\label{cha:ch_1}


\section{Архитектуры нейронных сетей для синтеза речи}
Современные решения для преобразования текста в речь в основном устроены следующим образом: (cм. Рисунок \ref{fig:tts_pipeline})

\begin{enumerate}
    \item В начале текст токенизируется - преобразуется из строкового формата в последовательность лексем - токенов
    \item токенизированный текст преобразуется с помощью нейросети-энкодера во внутреннее признаковое представление
    \item используя текстовые признаки, нейросеть генерирует признаковое представление звука или спектрограмму. Этот модуль может быть многоуровненвым и сложным в зависимости от архитектуры.
    \item признакове представление звука декодируется в звуковой сигнал.
\end{enumerate}

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/tts_pipeline}
  \caption{Преобразование текста в речь}
  \label{fig:tts_pipeline}
\end{figure}

Также помимо задачи преобразования текста в речь, существуют задачи замены голоса, генерации музыки, перевода с сохранением голоса и прочие.
Их пайплайн устроен похожим образом, но какие-то части могут отличаться. 
Отметим, что в любой из перечисленных задач неотъемлемой частью пайплайна является этап декодирования звука из признакового представления в аудиосигнал.




\subsection{Понятие спектрограммы}
Прежде чем продолжить рассмотрение современных подходов для синтеза речи, раскроем понятие спектрограммы.

\textbf{Спектрограмма} - это двумерный массив данных, представляющий из себя разложение сигнала по спектру, изменяющееся во времени.
Такое разложение можно получить например с помощью оконного преобразования Фурье или вейвлет-преобразования. 
По горизонитальной оси отложено время в линейной шкале. По вертикальной оси отложены частоты, в некоторой шкале, не обязательно линейной.
На практике используются линейная, логарифмическая и мел-шкала.
\begin{itemize}
  \item Линейная шкала используется обычно в обратимых алгоритмоах или как разложение для передачи многоканальной информации в одном сигнале.
  \item Логарифмическая шкала используется в музкальных приложениях и редакторах.
  \item мел-шкала используется для анализа голоса. Она построена на исследованиях чувствительности человеческого слуха к изменению частоты.
\end{itemize}

На рисунке \ref{fig:log_spec} изображен пример спектрограммы в логарифмической шкале, а на рисунке \ref{fig:mel_spec} - в мел-шкале.
\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/log_spec}
  \caption{Спектрограмма записи игры на металлофоне в логарифмической шкале частот с указанием нот}
  \label{fig:log_spec}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/mel_spec}
  \caption{Спектрограмма записи голоса в мел-шкале}
  \label{fig:mel_spec}
\end{figure}




\subsection{Классификация моделей}
Рассмотрим основные подходы, использующиеся в современных решениях синтеза речи и их классификацию.


\subsubsection{По формату промежуточного представления}
По формату промежуточного представления методы делятся на несколько типов:

\textbf{Генераторы спектрограмм} подразумевают генерацию спектрограммы с последующим преобразованием спектрограммы в звуковой сигнал. Примеры таких моделей:
\begin{itemize}
  \item Tacotron 2 (Google, 2017) \cite{Tacotron2} - классическая модель, использующая последовательное преобразование текста в мел-спектрограмму, с последующим применением вокодера для декодирвоания звука.
  \item FastSpeech 2 (Microsoft, 2019–2020) \cite{FastSpeech2} - Ускоренные и более стабильные версии Tacotron.
  \item Riffusion (2022) \cite{Riffusion} - Диффузионная модель, генерирующая песни и инструментальную музыку в виде спектрограмм с последующим декодированием в звук.
  \item TalkNet (2020, NVIDIA) \cite{TalkNet} - Полносверточная text-to-speech модель
\end{itemize}

\textbf{Генераторы в латентное представление} с последующим декодированием в звук с помощью нейронного декодера подразумевают 
генерацию латентного признакого представления, чем-то отдаленно схожего со спектрограммой, но сформированного отдельно обученным автоэнкодером.

\begin{itemize} 
  \item NaturalSpeech 2 (Microsoft, 2023) \cite{NaturalSpeech2} - Современная модель на основе латентных диффузий для синтеза речи и пения
  \item Kokoro-TTS (2025) \cite{kokoro}- это современная, компактная и высокоэффективная модель синтеза речи, разработанная для генерации естественного звучания при минимальных вычислительных затратах
\end{itemize}

\textbf{Генераторы токенов для нейронного кодека} схожи по принципу работы с генеративными трансформерами - основная генеративная модель создает последовательность токенов, 
которая потом преобразуется в звук с помощью нейросетевого кодека.

Пример такого кодека - EnCodec (Meta AI, 2022) \cite{encodec}. Он предназначен для сжатия и восстановления аудиосигналов, кодирует звук в дискретное латентное пространство (токены).

\begin{itemize} 
  \item Bark (Suno AI) \cite{SunoAI_Bark_2023} - Трансформерная генеративная модель, синтезирующая музыку и песни по заданному тексту и указаниям.
  \item Voicebox (2023, Meta AI) \cite{le2023voicebox} - Модель, способная генерировать, изменять и редактировать речь в различных стилях.
  \item VALL-E (Microsoft, 2023) \cite{Valle} - генерация речи с имитацией голоса на основе аудиопримера, на базе условной языковой модели.
\end{itemize}

\textbf{Одностадийные end-to-end аудиогенераторы} синтезируют звук напрямую, минуя стадию спектрограммы или отдельного декодера из латентного пространства.

\begin{itemize} 
  \item WaveNet (DeepMind, 2016) \cite{WaveNet} - Первая модель, которая напрямую генерировала звук по аудиосэмплам. Медленная, так как работает сэмпл за сэмплом (для аудио с частотой дискретизации 24 000 Гц — таких генераций должно быть 24 тысячи в секунду).
  \item DiffWave (Google, 2020) \cite{DiffWave} - Диффузионная модель, которая работает не со спектрограммой, а напрямую с аудиоволной. Высокое качество, но относительно медленная генерация.
\end{itemize}



\subsubsection{По принципу генерации промежуточного представления}
Если рассматривать принцип генерации промежуточного представления, то наиболее успешными являются трансформерные и диффузионные модели.
Также можно выделить полносверточные модели для обработки/восстановления звука, хотя существуют и полносверточные text-to-speech модели.


\textbf{Трансформерные генераторы} используют в качестве \textit{генератора} звукового представления GPT-подобный трансформер.
\begin{itemize}
  \item FastSpeech 2 (Microsoft, 2019–2020) \cite{FastSpeech2}
  \item Voicebox (2023, Meta AI) \cite{le2023voicebox}
  \item Bark (Suno AI) \cite{SunoAI_Bark_2023}
  \item Kokoro-TTS (2025) \cite{kokoro} - Поддерживает трансформеры в генераторе (настраиваемо)
  \item VALL-E (Microsoft, 2023) \cite{Valle} - генерация речи с имитацией голоса на основе аудиопримера, на базе условной языковой модели.
\end{itemize}

\textbf{Диффузионные генераторы} генерируют представление звука с помощью процесса обратной диффузии.
\begin{itemize}
  \item DiffWave (Google, 2020) \cite{DiffWave}
  \item NaturalSpeech 2 (Microsoft, 2023) \cite{NaturalSpeech2}
  \item Riffusion (2022) \cite{Riffusion}
\end{itemize}

\textbf{Полносверточные модели}
\begin{itemize} 
  \item TalkNet (2020, NVIDIA) \cite{TalkNet} - Полносверточная text-to-speech модель. В ней присутствуют отдельные полносверточные модели для предсказания длительности каждого текстового токена и модель для генерации спектрограмм. Очень быстрое обучение и синтез.
  \item Kokoro-TTS \cite{kokoro} в некоторых конфигурациях также может использовать полносверточный генератор с предсказанием длительности токенов, вместо трансформера.
  \item VoiceFixer (2022) \cite{VoiceFixer} - Восстановление повреждённой речи (например, из телефона, старых записей)
\end{itemize}


\section{Cуществующие вокодеры}
Среди существующих вокодеров, применяемых в современных системах синтеза речи, можно выделить следующие группы.

\textbf{Нейросетевые декодеры из спектрограммы} - HiFi-Gan \cite{hifigan}, WaveGlow \cite{WaveGlow} - восстанавливают звук из mel-спектрограммы
при помощи сверточных генеративных сетей. Информация в mel-спектрограмме может быть не полной или слегка искаженной, 
нейросеть все равно будет способна восстанавливать звук хорошего качества.

\textbf{Специализированные автоэнкодеры} - Сверточные сети, обученные под конкретную модель генератора. Так же способны генерировать звук хорошего качества, 
при этом часто работают быстрее, чем спектрограммные нейросетевые декодеры. Однако, под конкретную задачу и модель чаще всего требуется обучать отдельный 
автоэнкодер на большом объеме данных.

\textbf{Нейросетевые кодеки в дискретное латентное пространство} - EnCodec \cite{encodec} - кодирует звук в последовательность токенов. 
Может достигать хорошего качества в сочетании с трансформерами, и работает относительно быстро. Однако, в приложениях с большим разнообразием звуков и интонаций 
наблюдаются проблемы с качеством. А также этот кодек не работает с диффузионными и полносверточными генераторами.

\textbf{Алгоритмические декодеры из спектрограмм} - GriffinLim \cite{1164317} - Восстанавливает звук из спектрограммы (только магнитуды) в линейной шкале. 
Этот и другие алгоритмические декодеры могут восстанавливать звук точно без потерь. Но к сожалению при наложении небольших искажений,
пристуствующих в спектрограммах, сгенерированных нейросетью, появляются сильно заметные нежелательные артефакты (металлический звук, эхо), 
что делает такие декодеры неприменимыми в современных решениях. С другой стороны, такие декодеры заметно быстрее, чем нейросетевые, 
и могут быть использованы в приложениях для встраиваемых устройств с низкой вычислительной мощностью, когда можно пожертвовать качеством.


\subsection{Успехи и открытые проблемы}
Изучая успех упомянутых моделей среди сообщества и сравнивая качество синтезированного звука, можно сделать следующие выводы об успешности применения определенных технологий:

1. Существуют несколько технологий генерации звукового представления (диффузионные, трансформерные, полносверточные), способные синтезировать речь очень хорошего качества. Но такие технологии требуют больших вычислительных затрат. 
Есть оптимизированные решения, такие как Kokoro-TTS, достигающие высокого качества и высокой скорости работы за счет оптимизации архитектуры и размеров моделей, тщательной проработки и аккуратного обучения каждого компонента. 
Однако, у каждой технологии есть свои преимущества и недостатки, делающие ее более или менее пригодной для конкретной задачи.
Например: синтез музыки с множеством требований и указаний лучше всего удается диффузионным моделям. Полносверточные модели самые быстрые. 

2. Существует несколько типов вокодеров - использующие представление в виде спектрограммы, латентного представления, дискретного представления в виде токенов. Наилучшего качества в сочетании с нейросетями достигают нейросетевые вокодеры из латентного представления или спектрограммы. 
Алгоритмические вокодеры также существуют, но они неустойчивы к искажениям, которые неизбежно возникают при генерации представления с помощью нейросети, в результате чего появляются нежелательные артефакты.
Также для каждой технологии генерации подходит не любой тип промежуточного представления звука. Ниже рассмотрена совместимость технологий генерации с промежуточным представлением.

\begin{center}
\begin{tabular}{ c c c c }
                 & Спектрограмма & Латентное пр-е & Токены \\
    Диффузионные & +             & +              &        \\ 
  Трансформерные & +             & +              & +      \\  
 Полносверточные & +             & +              &     
\end{tabular}
\end{center}

Отсюда видно, что универсальными представлениями, работающими с любым типом генерации, являются спектрограмма и латентное векторное представление. 

3. Нейросетевой декодер из латентного пр-ва, обученный на одном наборе данных, 
может не подходить для применения на других данных (например на другом языке) или 
не подходить для конкретной задачи (учет интонации, акцента, персональности голоса говорящего).

4. Спектрограммные нейросетевые декодеры практически всегда требуют больших вычислительных затрат, чем из латентного пр-ва из-за избыточности информации. 
С другой стороны, в спектрограмме содержится достаточно информации для восстановления звука без потерь, 
и поэтому декодер из спектрограммы можно использовать для любой задачи, домена и технологии, и достигать наилучшего качества генерации.
Спектрограммное представление можно назвать \textit{универсальным} с точки зрения применимости технологии и задачи, но избыточным в плане вычислительных ресурсов 
(при использовании нейросетевого декодера).

5. Модели, генерирующие непосредственно звуковой сигнал, работают медленно и сложны в обучении. Практически всегда их можно разделить на две стадии - предобучение нейросетевого автоэнкодера в латентное пр-во и генерация на этом пр-ве.

6. Если бы существовал алгоритмический декодер спектрограммы, способный восстанавливать аудиосигнал с качеством, 
сопоставимым с современными нейросетевыми вокодерами, при этом устойчивый к искажениям во входных данных и обладающий более высокой скоростью работы на CPU, 
это могло бы упростить архитектуру TTS-систем, сократить вычислительные затраты и повысить доступность синтеза речи. 
Кроме того, использование стандартизированного формата спектрограмм позволило бы сосредоточить усилия на улучшении генератора, 
ускорить обучение и повысить воспроизводимость моделей.


\section{Спектральный анализ аудиосигналов}
В данном разделе рассмотрим теоретические основы алгоритмов построения спектрограмм и способы восстановления звукового сигнала из таких представлений.

Для начала рассмотрим \textbf{Оконное преобразование Фурье} или в англоязычной литературе Short-Time Fourier Transform (\textbf{STFT}) \cite{STFT}.

Оно представляет из себя двумерную функцию (от частоты и от времени), определяемую как преобразование Фурье от сигнала, умноженного на оконную функцию, сдвинутую во времени:

\begin{equation}
  \textbf{STFT}\{x(t)\} (\tau, \omega) = \int_{-\infty}^\infty x(t) w(t - \tau) e^{-i\omega t} dt
\end{equation}

Здесь \(w(t)\) - оконная функция. От ее выбора зависит разрешение спектрограммы по времени и по частоте. Иллюстрация работы STFT приведена на рисунке \ref{fig:mel_spec}.
В результате такого преобразования получается спектрограмма в линейной шкале, на которой можно увидеть, как разложение сигнала по частотам (спектр), изменяется во времени.

\begin{figure}
  \centering
  \includegraphics[width=16cm]{figures/stft}
  \caption{Оконное преобразование Фурье (STFT)}
  \label{fig:stft}
\end{figure}

На практике используется дискретное оконное преобразование Фурье.
\begin{equation}
  \textbf{STFT}\{x[n]\} (m, k) = \sum_{n=0}^{N-1} x[n] w[n - m] e^{-2\pi i  \frac{k n}{N}} = \textbf{DFT}\{x[m:m+N] * w\}(k)
\end{equation}
Алгоритм его построения обычно следующий - из сигнала \(x[n]\) вырезается отрезок длиной \(N\) отсчетов со сдвигом по времени \(m\) отсчетов. 
Результат ДПФ выделенной части сигнала, умноженной на окно, присоединяется к массиву. В результате получается массив \([M \times K]\), 
представляющий из себя спектрограмму, как на рисунке \ref{fig:stft}

\begin{wrapfigure}{r}{0.4\textwidth}
  \includegraphics[width=0.9\linewidth]{figures/wavelet}
  \caption{Временное и спектральное представления вейвлета Морле \cite{MorleWavelet}}
  \label{fig:wavelet}
\end{wrapfigure}

Несложно показать, что преобразование является линейным, как и ДПФ.
Также можно представить каждый элемент $\textbf{STFT}\{x[n]\} (m, k)$ как свертку сигнала $x[n]$ с вейвлетом $w[n - m] e^{-2\pi i  \frac{k n}{N}}$.
И всю спектрограмму можно построить с помощью вейвлет-преобразования. Более того, для каждой частоты вейвлета можно выбирать свою ширину окна: 
$\psi_{k,m}(n) = w_k[n - m] e^{-2\pi i  \frac{k n}{N}}$. По такому принципу построено вейвлет-преобразование на основе вейвлета Морле \cite{MorleWavelet}, 
окном которого выбрана Гауссовская функция с шириной в несколько периодов соответствующей частоты. Это преобразование обратимо, так же как и STFT.

Рассмотрим влияние оконных функций на разрешение по времени и частоте. 
Оконная функция необходима для локализации события во временной области. 
Спектр оконной функции покажет, насколько хорошо событие локализовано в частотной области.
Кроме того, широкий спектр окна с паразитными "хвостами" создает связанность отдаленных частот. 
Небольшое искажение на одной частоте сильно влияет на другие частоты из-за таких эффектов, если не согласовано с этими частотами, 
чтобы в резульате интерференции получалось нужное значение. Примеры оконных функций и их спектров рассмотрены на рисунке \ref{fig:windows}

\begin{figure}[t]
  \centering
  \includegraphics[width=16cm]{figures/windows}
  \caption{Сравнение оконных функций}
  \label{fig:windows}
\end{figure}

По отношению к оконным функциям, а также любым сигналам, над которыми производится спектральное преобразование, сущетвует принцип неопределенности, который гласит, что
для дифференцируемых вещественных сигналов 
$x(t)$ с энергией $E$, для которых интеграл 
$t_{0} = \int \limits _{-\infty }^{\infty }tx^{2}(t)dt$ сходится и $\lim _{t\to \pm \infty }tx^{2}(t)=0$, произведение эффективной длительности сигнала 
$\Delta t$ и эффективной ширины полосы частот сигнала $\Delta f$ ограничено снизу \cite{Umnyashkin}:
\begin{equation}
  \Delta t\Delta f\geq {\frac {E}{\pi }}}\]
\end{equation}
Равенство $\Delta t\Delta f={\frac {E}{\pi }}$ достигается только в случае гауссова импульса $x(t)=Ce^{-kt^{2}}$, где 
$k$ и $C$ - некоторые константы ($k>0$). \cite{Umnyashkin}

Это отношение применимо и к оконным функциям, и к вейвлетам, которые являются базисом для разложения. 
В контексте спектрограммы принцип неопределенности проявится в размытии образа сигналов на соседние частоты и времена с шириной $\Delta t$ и $\Delta f$.
Иллюстрацию этого явления можно увидеть на рисунке \ref{fig:windows}

Рассмотрим подробно окно в виде гауссовской функции. Его спектр представлен также гауссовской функцией. Хоть она и является инфинитной (не равна нулю на всей шкале времени),
но приближается к нулю с экспоненциальной скоростью. Хотя финитный сигнал не может иметь финитный спектр, 
такое окно вполне удовлетворяет практическим сценариям применения и имеет понятный физичиский смысл - локализация события имеет нормальное распределение.
Как было показано, Гауссовское окно обладает наилучшими характеристиками для локализации событий одновременно в частотной и во временной области.
Это окно используется в преобразовании Габора \cite{Gabor} (STFT с гауссовским окном) и вейвлетах Морле \cite{MorleWavelet}.

Кроме того, при использовании гауссовского окна в прямом и обратном преобразовании, искажения, наложеннные на спектрограмму в одном месте, наложат сильно ограниченные по времени и частоте изменения в сигнал 
(преобразование является линейным, поэтому его след в частотно-временном представлении будет результатом свертки окна с искажением), 
что придает обратному преобразованию большую устойчивость к искажениям, чем при использовании любого другого окна. 
Поэтому в данной работе предлагается использование именно гауссовского окна.


\begin{markdown}
 - децибел шкала амплитуд
   - почему такая
   - формула
   - порог слышимости
 - мел шкала частот
   - почему такая
   - формула
 - выбор оптимальной шкалы частот
  - линейная шкала
  - логарифмическая шкала
  - мел шкала
  - комбинированная шкала
 - оптимальный размер окна для конкретной шкалы частот
 - наложение по времени
 - наложение по частоте
 - избыточность информации в спектрограмме
 - восстановление сигнала с наложением (суммирование, сумма дает 0 там где надо, но хвосты могут расползаться)
 - сравнение с вейвлетами
 - оптимальная форма окна для устойчивости к искажениям
   - минимизация связанности далеких данных
 - Алгоритм Гриффина-Лима
    - как работает
\end{markdown}

\section{Устойчивость к трансформациям и артефактам}
\begin{markdown}
 - трансформации спектрограммы, устойчивость вокодера к трансформациям
   - растяжение\сжатие по времени
   - перемещение по шкале частот
   - вырезание\вставка куска
   - суммирование сигналов
 - от чего появляются трансформации и зачем нужны
 - артефакты от нейросетей
   - примеры полосок от сверток
   - BatchNorm паразитный bias
   - потеря шума
   - потеря outliers
 - устойчивость вокодеров к артефактам
 - инвариантность к сдвигу по времени, когда есть, зачем нужна
\end{markdown}

\section{Открытые проблемы}
\begin{markdown}
 - борьба за качество генерации
 - как восстанавливать сигнал с нелинейной шкалой частот, когда нет ортогонального базиса
 - нет алгоритма, который был бы достаточно устойчив к артефактам от нейросетей
 - нейросетевые вокодеры:
   - требуют вычислительных ресурсов
   - нужно обучать на больших объемах данных
   - часто завязаны на домен, для другого домена могут хуже работать
 - избыточность представлений, тащим лишнюю информацию
 - нужна устойчивость обучения, глубокие сети сложнее учить
\end{markdown}

\section{Выводы по главе}

